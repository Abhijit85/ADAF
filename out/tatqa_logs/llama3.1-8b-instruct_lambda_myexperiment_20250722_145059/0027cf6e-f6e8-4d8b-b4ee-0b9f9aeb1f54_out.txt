[RUN_AMAF] provider=lambda | model=llama3.1-8b-instruct
DEBUG: Initializing agent TabuSynth with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Initializing agent Contextron with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Initializing agent Visura with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Initializing agent SummaCraft with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Initializing agent TrendAnalyser with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Initializing agent MCP with provider=lambda, model=llama3.1-8b-instruct
DEBUG: _chat called with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Using OpenAI client.chat.completions.create() with model=llama3.1-8b-instruct
DEBUG: OpenAI API call successful, response type: <class 'openai.types.chat.chat_completion.ChatCompletion'>
DEBUG: _chat called with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Using OpenAI client.chat.completions.create() with model=llama3.1-8b-instruct
DEBUG: OpenAI API call successful, response type: <class 'openai.types.chat.chat_completion.ChatCompletion'>
DEBUG: _chat called with provider=lambda, model=llama3.1-8b-instruct
DEBUG: Using OpenAI client.chat.completions.create() with model=llama3.1-8b-instruct
